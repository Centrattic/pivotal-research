2025-08-17 19:55:48 Logging attempt 1 to ./logs/run_20250817_195548_attempt_1.log
2025-08-17 19:55:48 Starting (attempt 1) â†’ python -m src.main -c llama_mask_cpu
Loaded environment variables from /home/riya/pivotal/pivotal-research/evaluating-probes/.env

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=None
EP_BATCHED_NJOBS=32
====================================

Set CUDA_VISIBLE_DEVICES to 1, updated device to cuda:0

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=1
EP_BATCHED_NJOBS=32
====================================

[model_check] Clearing CUDA memory at start...
Updated device from cuda:1 to cuda:0
Processing 10 seeds: [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]
No llm_upsampling_experiments found, skipping LLM upsampling
Loading model 'meta-llama/Llama-3.3-70B-Instruct' for activation extraction...
Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]