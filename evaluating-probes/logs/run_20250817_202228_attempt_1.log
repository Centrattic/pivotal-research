2025-08-17 20:22:28 Logging attempt 1 to ./logs/run_20250817_202228_attempt_1.log
2025-08-17 20:22:28 Starting (attempt 1) → python -m src.main -c llama_mask_cpu
Loaded environment variables from /lambda/nfs/riya-probing/pivotal-research/evaluating-probes/.env

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=None
EP_BATCHED_NJOBS=2
====================================

Set CUDA_VISIBLE_DEVICES to 1, updated device to cuda:0

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=1
EP_BATCHED_NJOBS=2
====================================

Updated device from cuda:1 to cuda:0
Processing 10 seeds: [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]
No llm_upsampling_experiments found, skipping LLM upsampling
Loading model 'meta-llama/Llama-3.3-70B-Instruct' for activation extraction...
The 8-bit optimizer is not available on your device, only available on CUDA for now.
Fetching 30 files:   0%|                                                                           | 0/30 [00:00<?, ?it/s]Fetching 30 files:   3%|██▏                                                                | 1/30 [00:10<05:10, 10.69s/it]Fetching 30 files:   7%|████▍                                                              | 2/30 [00:14<03:00,  6.46s/it]Fetching 30 files:  10%|██████▋                                                            | 3/30 [00:14<01:39,  3.68s/it]Fetching 30 files:  30%|████████████████████                                               | 9/30 [00:18<00:27,  1.31s/it]Fetching 30 files:  33%|██████████████████████                                            | 10/30 [00:20<00:27,  1.39s/it]Fetching 30 files:  37%|████████████████████████▏                                         | 11/30 [00:23<00:30,  1.58s/it]Fetching 30 files:  40%|██████████████████████████▍                                       | 12/30 [00:24<00:26,  1.48s/it]Fetching 30 files:  43%|████████████████████████████▌                                     | 13/30 [00:24<00:21,  1.24s/it]Fetching 30 files:  47%|██████████████████████████████▊                                   | 14/30 [00:25<00:17,  1.09s/it]Fetching 30 files:  57%|█████████████████████████████████████▍                            | 17/30 [00:27<00:11,  1.13it/s]Fetching 30 files:  60%|███████████████████████████████████████▌                          | 18/30 [00:30<00:16,  1.35s/it]Fetching 30 files:  63%|█████████████████████████████████████████▊                        | 19/30 [00:34<00:20,  1.91s/it]Fetching 30 files:  67%|████████████████████████████████████████████                      | 20/30 [00:37<00:22,  2.27s/it]Fetching 30 files:  70%|██████████████████████████████████████████████▏                   | 21/30 [00:41<00:24,  2.69s/it]Fetching 30 files:  77%|██████████████████████████████████████████████████▌               | 23/30 [00:42<00:12,  1.73s/it]Fetching 30 files:  83%|███████████████████████████████████████████████████████           | 25/30 [00:43<00:06,  1.32s/it]Fetching 30 files:  87%|█████████████████████████████████████████████████████████▏        | 26/30 [00:45<00:05,  1.31s/it]Fetching 30 files:  90%|███████████████████████████████████████████████████████████▍      | 27/30 [00:48<00:05,  1.69s/it]Fetching 30 files:  93%|█████████████████████████████████████████████████████████████▌    | 28/30 [00:49<00:03,  1.72s/it]Fetching 30 files:  97%|███████████████████████████████████████████████████████████████▊  | 29/30 [00:50<00:01,  1.31s/it]Fetching 30 files: 100%|██████████████████████████████████████████████████████████████████| 30/30 [00:50<00:00,  1.67s/it]
================================================================================
😜 Run finished. Closing log file.
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/lambda/nfs/riya-probing/pivotal-research/evaluating-probes/src/main.py", line 1002, in <module>
    main()
  File "/lambda/nfs/riya-probing/pivotal-research/evaluating-probes/src/main.py", line 938, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4839, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5260, in _load_pretrained_model
    caching_allocator_warmup(model_to_load, expanded_device_map, hf_quantizer)
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5861, in caching_allocator_warmup
    device_memory = torch.cuda.mem_get_info(index)[0]
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/torch/cuda/memory.py", line 738, in mem_get_info
    return torch.cuda.cudart().cudaMemGetInfo(device)
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/torch/cuda/__init__.py", line 396, in cudart
    _lazy_init()
  File "/lambda/nfs/riya-probing/pivotal-research/pivotal_env/lib/python3.10/site-packages/torch/cuda/__init__.py", line 319, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
2025-08-17 20:23:47 Command exited with status 1. Will restart.
2025-08-17 20:23:47 Sleeping 1s before restart #1...
