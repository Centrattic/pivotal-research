2025-08-17 21:27:07 Logging attempt 40 to ./logs/run_20250817_212707_attempt_40.log
2025-08-17 21:27:07 Starting (attempt 40) â†’ python -m src.main -c llama_mask_cpu
Loaded environment variables from /lambda/nfs/riya-probing/pivotal-research/evaluating-probes/.env

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=None
EP_BATCHED_NJOBS=2
====================================

Set CUDA_VISIBLE_DEVICES to 0, updated device to cuda:0

=== DEBUG: Environment Variables ===
OPENAI_API_KEY=sk**************************************************************************************************************************************************************VwIA
OMP_NUM_THREADS=1
CUDA_VISIBLE_DEVICES=0
EP_BATCHED_NJOBS=2
====================================

[model_check] Clearing CUDA memory at start...
Processing 10 seeds: [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]
No llm_upsampling_experiments found, skipping LLM upsampling
Loading model 'meta-llama/Llama-3.3-70B-Instruct' for activation extraction...
2025-08-17 21:27:33 Caught termination signal. Exiting.
