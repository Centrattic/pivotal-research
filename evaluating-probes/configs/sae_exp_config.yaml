run_name: "sae_probe_experiment"
device: "cuda:0"
model_name: "google/gemma-2-9b"
layers: [20]  # Layer where SAE probes are typically most effective
components: ["resid_post"]

architectures:
  - name: "sae_16k_l0_189_mean"
    config_name: "sae_16k_l0_189_mean"

seeds: [42]

# Test SAE probes on spam dataset
experiments:
  - name: sae_spam_test
    metric: auc
    class_names: {0: "Not Spam", 1: "Spam"}
    train_on: 87_is_spam
    evaluate_on:
      - 87_is_spam
    score:
      - all
      - filtered

use_cache: true
retrain: false
reevaluate: false
hyperparameter_tuning: false
retrain_with_best_hparams: false 